{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gourdy09/machine_learning_certification_code/blob/main/fcc_sms_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "trdf = pd.read_csv(train_file_path, sep=\"\\t\")\n",
        "tedf = pd.read_csv(test_file_path, sep=\"\\t\")\n",
        "\n",
        "trdf.columns = ['target', 'msg']\n",
        "tedf.columns = ['target', 'msg']\n",
        "\n",
        "trdf['target'] = trdf['target'].map({'ham': 0, 'spam': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "trdf.sample(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trdf.shape"
      ],
      "metadata": {
        "id": "IrZpYcq2_18s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.countplot(x='target', data=trdf)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aRdUzXB_AA3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# balance data because too many ham not enough spam\n",
        "ham_msg = trdf[trdf.target == 0]\n",
        "spam_msg = trdf[trdf.target == 1]\n",
        "ham_msg = ham_msg.sample(n=len(spam_msg), random_state=42)\n",
        "\n",
        "balanced_data = pd.concat([ham_msg, spam_msg]).reset_index(drop=True)\n",
        "sns.countplot(data = balanced_data, x='target')"
      ],
      "metadata": {
        "id": "DIBnSYsFCxcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up punctuation\n",
        "def remove_punc(text : string):\n",
        "  temp = str.maketrans('', '', string.punctuation)\n",
        "  return text.translate(temp)\n",
        "\n",
        "balanced_data['msg'] = balanced_data['msg'].apply(lambda x: remove_punc(x))\n",
        "balanced_data.head()"
      ],
      "metadata": {
        "id": "fZMggiyvDrvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def remove_stopwords(text : string):\n",
        "  imp_words = []\n",
        "\n",
        "  for word in str(text).split():\n",
        "    word = word.lower()\n",
        "    if word not in stopwords.words('english'):\n",
        "      imp_words.append(word)\n",
        "  output = \" \".join(imp_words)\n",
        "  return output\n",
        "\n",
        "balanced_data['msg'] = balanced_data['msg'].apply(lambda text: remove_stopwords(text))\n",
        "balanced_data.head()"
      ],
      "metadata": {
        "id": "_Bw-9B9ZEKTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = trdf.msg\n",
        "y = trdf.target\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "train_sequences = pad_sequences(train_sequences, maxlen=50, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "8uxJrZXNE2Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
        "                                    output_dim=32,\n",
        "                                    input_length=50))\n",
        "model.add(tf.keras.layers.LSTM(64))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')\n",
        "es = EarlyStopping(patience=3,\n",
        "                   monitor = 'val_accuracy',\n",
        "                   restore_best_weights = True)\n",
        "\n",
        "lr = ReduceLROnPlateau(patience = 3,\n",
        "                       monitor = 'val_loss',\n",
        "                       factor = 0.8,\n",
        "                       verbose = 0)\n",
        "\n",
        "history = model.fit(train_sequences, y,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    callbacks = [lr, es],\n",
        "                    shuffle = True\n",
        "                   )"
      ],
      "metadata": {
        "id": "ewAE6ty_FNkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  # Tokenize the string into a sequence of integers\n",
        "  text_input = tokenizer.texts_to_sequences([pred_text])  # Wrapping pred_text in a list\n",
        "\n",
        "# Pad the sequence to make sure it's the right length\n",
        "  text_input = pad_sequences(text_input, maxlen=50, padding='post', truncating='post')\n",
        "\n",
        "# Predict using the model\n",
        "  prediction = model.predict(text_input)\n",
        "\n",
        "  return [prediction[0][0], 'spam' if prediction >= 0.0013670842 else 'ham']\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    print(prediction)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}